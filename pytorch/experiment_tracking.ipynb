{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2f8a1cf-514d-4173-99c1-4772beb582c4",
   "metadata": {},
   "source": [
    "## PyTorch Experiment tracking.\n",
    "\n",
    "Helps track the experiments and figure out what does not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1a0689aa-1afd-4ceb-a900-173a987b4b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126\n",
      "0.21.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "\n",
    "from going_modular import data_setup, engine\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b2efe8f-abbb-4daa-bf1d-08fee5178757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d55dc44-140f-43d7-a127-afa7bcda71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ca0001f-9070-40fa-96d0-e65c1091f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cffb398-6671-4d4c-a19d-b7c1b49b907f",
   "metadata": {},
   "source": [
    "## Get data\n",
    "\n",
    "Want to get pizza, steak and sushi images.\n",
    "\n",
    "So we can run experiment and track the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e850b13b-4a35-44b5-b008-fd49f4f8114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "def download_data(source: str,\n",
    "                 destination: str,\n",
    "                 removed_source: bool = True) -> Path:\n",
    "    \"\"\"Downloads a zipped dataset from source and unzips to destination.\"\"\"\n",
    "\n",
    "    # Setup path to data folder\n",
    "    data_path = Path(\"data/\")\n",
    "    image_path = data_path/destination\n",
    "\n",
    "    #If image folder doesn't exist, create it\n",
    "    if image_path.is_dir():\n",
    "        print(f\"[INFO] {image_path} directory already exists\")\n",
    "    else:\n",
    "        print(f\"[INFO] could not find {image_path} , creating one...\")\n",
    "        image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Download the target data\n",
    "        target_file = Path(source).name\n",
    "        with open(data_path/target_file, \"wb\") as f:\n",
    "            request = requests.get(source)\n",
    "            print(f\"[INFO] Downloading {target_file} from {source}...\")\n",
    "            f.write(request.content)\n",
    "\n",
    "        #Unzip target file\n",
    "        with zipfile.ZipFile(data_path/target_file, \"r\") as zip_ref:\n",
    "            print(f\"[INFO] Unzipping\")\n",
    "            zip_ref.extractall(image_path)\n",
    "\n",
    "        # Remove the .zip file\n",
    "        if removed_source:\n",
    "            os.remove(data_path/target_file)\n",
    "\n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5847869-8083-450f-99af-df86efabdb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data\\pizza_steak_sushi directory already exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/pizza_steak_sushi')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/refs/heads/main/data/pizza_steak_sushi.zip\",\n",
    "                          destination=\"pizza_steak_sushi\")\n",
    "image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c7e23-a6db-4130-a71e-6378174d8e13",
   "metadata": {},
   "source": [
    "## Create datasets and dataloaders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93721b5e-f841-4538-86a1-4ddbe4290057",
   "metadata": {},
   "source": [
    "### Create data loaders with manual transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7716a197-3d35-4c5f-b55b-5256967d29b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/pizza_steak_sushi')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc89d4cc-3b7b-4d67-b577-f029eb6abe6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/pizza_steak_sushi/train'),\n",
       " WindowsPath('data/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup directores\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "674afad9-483c-4829-997e-ed9221bd11f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual tranforms Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x25356824f40>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x25356825ba0>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create transform pipeline manually\n",
    "from torchvision import transforms\n",
    "\n",
    "# Setup ImageNet normalization levels\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "print(f\"Manual tranforms {manual_transforms}\")\n",
    "\n",
    "# Cretae DataLoaders\n",
    "from going_modular import data_setup\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                              test_dir=test_dir,\n",
    "                                                                              transform=manual_transforms,\n",
    "                                                                              batch_size=32)\n",
    "\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d4ec5-1c32-42e6-84c9-8b5127c9fe9a",
   "metadata": {},
   "source": [
    "## Create Dataloaders using automatic transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "64776e36-a335-41f5-8872-c37b31196b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BICUBIC\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x25356825660>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x25356825ba0>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup dirs\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "# Setup the pretrained weights\n",
    "import torchvision\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "\n",
    "# Get the tranforms from weights\n",
    "automatic_tranforms = weights.transforms()\n",
    "print(automatic_tranforms)\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader, test_dataloaders, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                               test_dir=test_dir,\n",
    "                                                                               transform=automatic_tranforms,\n",
    "                                                                               batch_size=32)\n",
    "\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caee042-bfb3-4475-af1f-c7b64a14dd37",
   "metadata": {},
   "source": [
    "# Get a pretrained model and freeze the base layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a66e1968-14a1-4464-9ab5-cb5e6457e4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fe5539af-30dc-4bc9-88c8-6c165f08e51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New method of creating a pretrained model (torchvision v0.13+)\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT  # DEFAULT is best available weights\n",
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "52c7292d-0c78-4f9e-9efa-2ca40df18495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveAvgPool2d(output_size=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.avgpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "833c0752-a105-42f9-b40c-42286fde2be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=True)\n",
       "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d75fcc47-054d-4ba1-98c8-41e3ba8d32a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [1, 3, 224, 224]     [1, 1000]            --                   True\n",
       "├─Sequential (features)                                      [1, 3, 224, 224]     [1, 1280, 7, 7]      --                   True\n",
       "│    └─Conv2dNormActivation (0)                              [1, 3, 224, 224]     [1, 32, 112, 112]    --                   True\n",
       "│    │    └─Conv2d (0)                                       [1, 3, 224, 224]     [1, 32, 112, 112]    864                  True\n",
       "│    │    └─BatchNorm2d (1)                                  [1, 32, 112, 112]    [1, 32, 112, 112]    64                   True\n",
       "│    │    └─SiLU (2)                                         [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
       "│    └─Sequential (1)                                        [1, 32, 112, 112]    [1, 16, 112, 112]    --                   True\n",
       "│    │    └─MBConv (0)                                       [1, 32, 112, 112]    [1, 16, 112, 112]    1,448                True\n",
       "│    └─Sequential (2)                                        [1, 16, 112, 112]    [1, 24, 56, 56]      --                   True\n",
       "│    │    └─MBConv (0)                                       [1, 16, 112, 112]    [1, 24, 56, 56]      6,004                True\n",
       "│    │    └─MBConv (1)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      10,710               True\n",
       "│    └─Sequential (3)                                        [1, 24, 56, 56]      [1, 40, 28, 28]      --                   True\n",
       "│    │    └─MBConv (0)                                       [1, 24, 56, 56]      [1, 40, 28, 28]      15,350               True\n",
       "│    │    └─MBConv (1)                                       [1, 40, 28, 28]      [1, 40, 28, 28]      31,290               True\n",
       "│    └─Sequential (4)                                        [1, 40, 28, 28]      [1, 80, 14, 14]      --                   True\n",
       "│    │    └─MBConv (0)                                       [1, 40, 28, 28]      [1, 80, 14, 14]      37,130               True\n",
       "│    │    └─MBConv (1)                                       [1, 80, 14, 14]      [1, 80, 14, 14]      102,900              True\n",
       "│    │    └─MBConv (2)                                       [1, 80, 14, 14]      [1, 80, 14, 14]      102,900              True\n",
       "│    └─Sequential (5)                                        [1, 80, 14, 14]      [1, 112, 14, 14]     --                   True\n",
       "│    │    └─MBConv (0)                                       [1, 80, 14, 14]      [1, 112, 14, 14]     126,004              True\n",
       "│    │    └─MBConv (1)                                       [1, 112, 14, 14]     [1, 112, 14, 14]     208,572              True\n",
       "│    │    └─MBConv (2)                                       [1, 112, 14, 14]     [1, 112, 14, 14]     208,572              True\n",
       "│    └─Sequential (6)                                        [1, 112, 14, 14]     [1, 192, 7, 7]       --                   True\n",
       "│    │    └─MBConv (0)                                       [1, 112, 14, 14]     [1, 192, 7, 7]       262,492              True\n",
       "│    │    └─MBConv (1)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       587,952              True\n",
       "│    │    └─MBConv (2)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       587,952              True\n",
       "│    │    └─MBConv (3)                                       [1, 192, 7, 7]       [1, 192, 7, 7]       587,952              True\n",
       "│    └─Sequential (7)                                        [1, 192, 7, 7]       [1, 320, 7, 7]       --                   True\n",
       "│    │    └─MBConv (0)                                       [1, 192, 7, 7]       [1, 320, 7, 7]       717,232              True\n",
       "│    └─Conv2dNormActivation (8)                              [1, 320, 7, 7]       [1, 1280, 7, 7]      --                   True\n",
       "│    │    └─Conv2d (0)                                       [1, 320, 7, 7]       [1, 1280, 7, 7]      409,600              True\n",
       "│    │    └─BatchNorm2d (1)                                  [1, 1280, 7, 7]      [1, 1280, 7, 7]      2,560                True\n",
       "│    │    └─SiLU (2)                                         [1, 1280, 7, 7]      [1, 1280, 7, 7]      --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [1, 1280, 7, 7]      [1, 1280, 1, 1]      --                   --\n",
       "├─Sequential (classifier)                                    [1, 1280]            [1, 1000]            --                   True\n",
       "│    └─Dropout (0)                                           [1, 1280]            [1, 1280]            --                   --\n",
       "│    └─Linear (1)                                            [1, 1280]            [1, 1000]            1,281,000            True\n",
       "============================================================================================================================================\n",
       "Total params: 5,288,548\n",
       "Trainable params: 5,288,548\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 385.87\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 107.89\n",
       "Params size (MB): 21.15\n",
       "Estimated Total Size (MB): 129.64\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a summary with torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model=model,\n",
    "       input_size=(1, 3, 224, 224),\n",
    "       col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "       col_width=20,\n",
    "       row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dbf5ef-bbd6-4418-8a96-d65661ae84d7",
   "metadata": {},
   "source": [
    "### Freezing the base model and changing the output layer to suit our needs\n",
    "\n",
    "We freeze the base layers and train the output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0701fffa-4eff-4a6f-b51b-c0d3c036183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all of the base layers in EffNetB0\n",
    "for param in model.features.parameters():\n",
    "    # print(param)\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27d1d33e-9274-4ee6-9b61-2531cacff936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "98e9ec4a-ae82-4de6-a313-84257d59e106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=True)\n",
       "  (1): Linear(in_features=1280, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Update the classifier head of model to suit our problem\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280,\n",
    "             out_features=len(class_names))\n",
    ").to(device)\n",
    "\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "145c466c-553e-4f88-bc42-f5c06451eafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 3]              --                   Partial\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   (864)                False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   (64)                 False\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   (1,448)              False\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     (6,004)              False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     (15,350)             False\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     (31,290)             False\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     (37,130)             False\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    (126,004)            False\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      (262,492)            False\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      (717,232)            False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     (409,600)            False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     (2,560)              False\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1280]           [32, 3]              --                   True\n",
       "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1280]           [32, 3]              3,843                True\n",
       "============================================================================================================================================\n",
       "Total params: 4,011,391\n",
       "Trainable params: 3,843\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (G): 12.31\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.09\n",
       "Params size (MB): 16.05\n",
       "Estimated Total Size (MB): 3487.41\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model,\n",
    "       input_size=(32, 3, 224, 224),\n",
    "       col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "       col_width=20,\n",
    "       row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6bd40c-c0e0-4167-81dd-68b69bbd3fb3",
   "metadata": {},
   "source": [
    "## Train a single model and track results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "436adc2d-6595-4212-b0b2-e3a2d803d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b65d08f-6a8d-44d9-8fb4-5d2fbb215443",
   "metadata": {},
   "source": [
    "To track experiment we are going to use tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c6a3bf1-ace5-454f-b8bf-419b8b6c7d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.tensorboard.writer.SummaryWriter at 0x25345ca6470>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup a SummaryWriter\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a076201d-fdec-4700-90dc-b241b559d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from going_modular.engine import train_step, test_step\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List[float]]:\n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "    \n",
    "    Passes a target PyTorch models through train_step() and test_step()\n",
    "    functions for a number of epochs, training and testing the model\n",
    "    in the same epoch loop.\n",
    "    \n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "    \n",
    "    Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "    \n",
    "    Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "              train_acc: [...],\n",
    "              test_loss: [...],\n",
    "              test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "             {train_loss: [2.0616, 1.0537],\n",
    "              train_acc: [0.3945, 0.3945],\n",
    "              test_loss: [1.2641, 1.5706],\n",
    "              test_acc: [0.3400, 0.2973]} \n",
    "    \"\"\"\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"test_loss\": [],\n",
    "    \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "          dataloader=test_dataloader,\n",
    "          loss_fn=loss_fn,\n",
    "          device=device)\n",
    "        \n",
    "        # Print out what's happening\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "        \n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        \n",
    "        ## New: Experiment tracking\n",
    "        writer.add_scalars(main_tag=\"Loss\",\n",
    "                        tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                        \"test_loss\": test_loss},\n",
    "                         global_step=epoch)\n",
    "        \n",
    "        writer.add_scalars(main_tag=\"Accuracy\",\n",
    "                        tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                        \"test_acc\": test_acc},\n",
    "                        global_step=epoch)\n",
    "        \n",
    "        writer.add_graph(model=model,\n",
    "                      input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
    "\n",
    "    ## Close the writer\n",
    "    writer.close()\n",
    "\n",
    "    \n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5ec4fabd-86af-4f9f-8af7-9b9bf8cf63de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c586ff47c54a938cf241696740a8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.5407 | train_acc: 0.9180 | test_loss: 0.6289 | test_acc: 0.8160\n",
      "Epoch: 2 | train_loss: 0.5485 | train_acc: 0.7969 | test_loss: 0.6050 | test_acc: 0.8021\n",
      "Epoch: 3 | train_loss: 0.5365 | train_acc: 0.8125 | test_loss: 0.5342 | test_acc: 0.8299\n",
      "Epoch: 4 | train_loss: 0.4608 | train_acc: 0.9297 | test_loss: 0.5228 | test_acc: 0.9306\n",
      "Epoch: 5 | train_loss: 0.4962 | train_acc: 0.7812 | test_loss: 0.5652 | test_acc: 0.8368\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# Using the modified train function\n",
    "set_seeds()\n",
    "results = train(model=model,\n",
    "               train_dataloader=train_dataloader,\n",
    "               test_dataloader=test_dataloader,\n",
    "               optimizer=optimizer,\n",
    "               loss_fn=loss_fn,\n",
    "               epochs=5,\n",
    "               device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5319c6c8-b60f-4a08-bbfe-19710c9e6da0",
   "metadata": {},
   "source": [
    "## View our models results with tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10471196-b64e-4f48-a695-196fb51982a6",
   "metadata": {},
   "source": [
    "## View our models results with tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "805dbb65-7e7b-4a49-921d-b3d256dde75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-658437218befc30\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-658437218befc30\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fbe7cd-005f-484d-9b51-8977a37d6932",
   "metadata": {},
   "source": [
    "## Create a function to prepare a `SummaryWriter()` instance\n",
    "\n",
    "How about saving different experiments to different folders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3c6536ed-5d6b-496a-aea6-32f9d0e5a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def create_writer(experiment_name: str,\n",
    "                 model_name: str,\n",
    "                 extra: str = None):\n",
    "    \"\"\"Create a torch.utils.tensorboard.writer.SummaryWriter() instance tracking to a specific directory.\"\"\"\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "\n",
    "    # Get timestamp of current dat in reverse order\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    if extra:\n",
    "        # create log directory path\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
    "    else:\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
    "\n",
    "    return SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5710e17a-530a-4ae6-9a26-8d2c366317dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.tensorboard.writer.SummaryWriter at 0x253a5e760b0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_writer = create_writer(experiment_name=\"data_10_percent\",\n",
    "                              model_name=\"effnetb0\",\n",
    "                              extra=\"5_epochs\")\n",
    "example_writer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf545e2-eead-486e-a8eb-61b7a9db9154",
   "metadata": {},
   "source": [
    "## Update the train function to include the writer parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9e0471ab-b036-4a7c-8380-95ddda53122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from going_modular.engine import train_step, test_step\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "         writer: torch.utils.tensorboard.writer.SummaryWriter) -> Dict[str, List[float]]:\n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "    \n",
    "    Passes a target PyTorch models through train_step() and test_step()\n",
    "    functions for a number of epochs, training and testing the model\n",
    "    in the same epoch loop.\n",
    "    \n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "    \n",
    "    Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "    \n",
    "    Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "              train_acc: [...],\n",
    "              test_loss: [...],\n",
    "              test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "             {train_loss: [2.0616, 1.0537],\n",
    "              train_acc: [0.3945, 0.3945],\n",
    "              test_loss: [1.2641, 1.5706],\n",
    "              test_acc: [0.3400, 0.2973]} \n",
    "    \"\"\"\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"test_loss\": [],\n",
    "    \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "          dataloader=test_dataloader,\n",
    "          loss_fn=loss_fn,\n",
    "          device=device)\n",
    "        \n",
    "        # Print out what's happening\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "        \n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        \n",
    "        ## New: Experiment tracking\n",
    "        if writer:\n",
    "            writer.add_scalars(main_tag=\"Loss\",\n",
    "                            tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                            \"test_loss\": test_loss},\n",
    "                             global_step=epoch)\n",
    "            \n",
    "            writer.add_scalars(main_tag=\"Accuracy\",\n",
    "                            tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                            \"test_acc\": test_acc},\n",
    "                            global_step=epoch)\n",
    "            \n",
    "            writer.add_graph(model=model,\n",
    "                          input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
    "\n",
    "            ## Close the writer\n",
    "            writer.close()\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5343c4-5010-4e80-9cf2-548ef80345df",
   "metadata": {},
   "source": [
    "## Setting up a series of modelling experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e987bb-6c20-4164-b373-9d0c800d4e3c",
   "metadata": {},
   "source": [
    "### What kind of experiments should you run?\n",
    "\n",
    "- Change number of epocs\n",
    "- Change number of hidden layers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b35e94-4f35-4fed-9a22-c70f2c3cadeb",
   "metadata": {},
   "source": [
    "## What experiments we are going to do.\n",
    "\n",
    "We are going to try 3 things:\n",
    "- model size - EffnetB0 vs EffnetB2\n",
    "- dataset size - 10% of pizza, sushi , steak vs 20%\n",
    "- training time - 5 vs 10 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec179c5d-5000-414d-bae7-e1ef133d337f",
   "metadata": {},
   "source": [
    "### Download different datasets\n",
    "\n",
    "We want 2 datasets 10% and 20% of pizza steak sushi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fedddcc1-81b1-4081-8fc7-dda36f2e8f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data\\pizza_steak_sushi directory already exists\n",
      "[INFO] could not find data\\pizza_steak_sushi_20_percent , creating one...\n",
      "[INFO] Downloading pizza_steak_sushi_20_percent.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/refs/heads/main/data/pizza_steak_sushi_20_percent.zip...\n",
      "[INFO] Unzipping\n"
     ]
    }
   ],
   "source": [
    "# Download 10 and 20 percent datasets\n",
    "data_10_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/refs/heads/main/data/pizza_steak_sushi.zip\",\n",
    "                                    destination=\"pizza_steak_sushi\")\n",
    "\n",
    "data_20_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/refs/heads/main/data/pizza_steak_sushi_20_percent.zip\",\n",
    "                                    destination=\"pizza_steak_sushi_20_percent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0f10fb-5c64-44d8-9a5c-c5ddb6a1133f",
   "metadata": {},
   "source": [
    "## Tranform datasets and create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f57c6002-6b1f-4a91-ad41-f6eeac8d897e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/pizza_steak_sushi/train'),\n",
       " WindowsPath('data/pizza_steak_sushi_20_percent/train'),\n",
       " WindowsPath('data/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup training dir path\n",
    "train_dir_10_percent = data_10_percent_path / \"train\"\n",
    "train_dir_20_percent = data_20_percent_path / \"train\"\n",
    "\n",
    "# Setup test dir\n",
    "test_dir = data_10_percent_path / \"test\"\n",
    "\n",
    "train_dir_10_percent, train_dir_20_percent, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "45af636c-3dfa-4ec9-8577-12e35840c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup ImageNet normalization levels\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "simple_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d02a10b2-b188-4c09-8bcc-35de3443a45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size 32 in 10% 8\n",
      "batch size 32 in 120% 15\n",
      "batch size 32 in 10% 3\n",
      "['pizza', 'steak', 'sushi']\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create 10% training and test DataLoaders\n",
    "train_dataloader_10_percent, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir_10_percent,\n",
    "                                                                                         test_dir=test_dir,\n",
    "                                                                                         transform=simple_transforms,\n",
    "                                                                                         batch_size=BATCH_SIZE)\n",
    "\n",
    "# Create 20% training and test dataloaders\n",
    "train_dataloader_20_percent, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir_20_percent,\n",
    "                                                                                         test_dir=test_dir,\n",
    "                                                                                         transform=simple_transforms,\n",
    "                                                                                         batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f\"batch size {BATCH_SIZE} in 10% {len(train_dataloader_10_percent)}\")\n",
    "print(f\"batch size {BATCH_SIZE} in 120% {len(train_dataloader_20_percent)}\")\n",
    "print(f\"batch size {BATCH_SIZE} in 10% {len(test_dataloaders)}\")\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea9321-25d2-4e39-a614-576cbe500b3e",
   "metadata": {},
   "source": [
    "### Create feature extractor models\n",
    "\n",
    "We want two functions\n",
    "- Create a torchvision.model.efficientnet_b0 with frozen base layers and custom classifier.\n",
    "- Create a torchvision.model.efficientnet_b2 with frozen base layers and custom classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5b9ae692-cae8-4476-9471-dda517872628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "# Create an EffnetB2\n",
    "effnetb2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
    "effnetb2 = torchvision.models.efficientnet_b2(weights=effnetb2_weights)\n",
    "\n",
    "# effnetb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5d0d65c1-c5e0-4985-b77f-bc0db6400058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 1000]           --                   True\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1408, 7, 7]     --                   True\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   864                  True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   64                   True\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   1,448                True\n",
       "│    │    └─MBConv (1)                                       [32, 16, 112, 112]   [32, 16, 112, 112]   612                  True\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     6,004                True\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     10,710               True\n",
       "│    │    └─MBConv (2)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     10,710               True\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 48, 28, 28]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 48, 28, 28]     16,518               True\n",
       "│    │    └─MBConv (1)                                       [32, 48, 28, 28]     [32, 48, 28, 28]     43,308               True\n",
       "│    │    └─MBConv (2)                                       [32, 48, 28, 28]     [32, 48, 28, 28]     43,308               True\n",
       "│    └─Sequential (4)                                        [32, 48, 28, 28]     [32, 88, 14, 14]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 48, 28, 28]     [32, 88, 14, 14]     50,300               True\n",
       "│    │    └─MBConv (1)                                       [32, 88, 14, 14]     [32, 88, 14, 14]     123,750              True\n",
       "│    │    └─MBConv (2)                                       [32, 88, 14, 14]     [32, 88, 14, 14]     123,750              True\n",
       "│    │    └─MBConv (3)                                       [32, 88, 14, 14]     [32, 88, 14, 14]     123,750              True\n",
       "│    └─Sequential (5)                                        [32, 88, 14, 14]     [32, 120, 14, 14]    --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 88, 14, 14]     [32, 120, 14, 14]    149,158              True\n",
       "│    │    └─MBConv (1)                                       [32, 120, 14, 14]    [32, 120, 14, 14]    237,870              True\n",
       "│    │    └─MBConv (2)                                       [32, 120, 14, 14]    [32, 120, 14, 14]    237,870              True\n",
       "│    │    └─MBConv (3)                                       [32, 120, 14, 14]    [32, 120, 14, 14]    237,870              True\n",
       "│    └─Sequential (6)                                        [32, 120, 14, 14]    [32, 208, 7, 7]      --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 120, 14, 14]    [32, 208, 7, 7]      301,406              True\n",
       "│    │    └─MBConv (1)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      686,868              True\n",
       "│    │    └─MBConv (2)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      686,868              True\n",
       "│    │    └─MBConv (3)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      686,868              True\n",
       "│    │    └─MBConv (4)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      686,868              True\n",
       "│    └─Sequential (7)                                        [32, 208, 7, 7]      [32, 352, 7, 7]      --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 208, 7, 7]      [32, 352, 7, 7]      846,900              True\n",
       "│    │    └─MBConv (1)                                       [32, 352, 7, 7]      [32, 352, 7, 7]      1,888,920            True\n",
       "│    └─Conv2dNormActivation (8)                              [32, 352, 7, 7]      [32, 1408, 7, 7]     --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 352, 7, 7]      [32, 1408, 7, 7]     495,616              True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1408, 7, 7]     [32, 1408, 7, 7]     2,816                True\n",
       "│    │    └─SiLU (2)                                         [32, 1408, 7, 7]     [32, 1408, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1408, 7, 7]     [32, 1408, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1408]           [32, 1000]           --                   True\n",
       "│    └─Dropout (0)                                           [32, 1408]           [32, 1408]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1408]           [32, 1000]           1,409,000            True\n",
       "============================================================================================================================================\n",
       "Total params: 9,109,994\n",
       "Trainable params: 9,109,994\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 21.09\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 5017.79\n",
       "Params size (MB): 36.44\n",
       "Estimated Total Size (MB): 5073.49\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=effnetb2,\n",
    "       input_size=(32, 3, 224, 224),\n",
    "       col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "       col_width=20,\n",
    "       row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f35cfb00-661e-41c5-b83d-1d29d2bcba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "OUT_FEATURES = len(class_names)\n",
    "\n",
    "# Cretae an EffNetB0 feature extractor\n",
    "def create_effnetb0():\n",
    "    # Get the weight and setup the model\n",
    "    weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "    model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "\n",
    "    # Freeze the base model layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Change the classifier head\n",
    "    set_seeds()\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(in_features=1280, out_features=OUT_FEATURES)\n",
    "    ).to(device)\n",
    "\n",
    "    # Give model a name\n",
    "    model.name = \"effnetb0\"\n",
    "    print(f\"[INFO] Created model {model.name} model...\")\n",
    "    return model\n",
    "\n",
    "# Cretae an EffNetB2 feature extractor\n",
    "def create_effnetb2():\n",
    "    # Get the weight and setup the model\n",
    "    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
    "    model = torchvision.models.efficientnet_b2(weights=weights).to(device)\n",
    "\n",
    "    # Freeze the base model layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Change the classifier head\n",
    "    set_seeds()\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=True),\n",
    "        nn.Linear(in_features=1408, out_features=OUT_FEATURES)\n",
    "    ).to(device)\n",
    "\n",
    "    # Give model a name\n",
    "    model.name = \"effnetb2\"\n",
    "    print(f\"[INFO] Created model {model.name} model...\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6dfed006-af0f-47c6-8bf2-2084f4b6425f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created model effnetb2 model...\n",
      "[INFO] Created model effnetb0 model...\n"
     ]
    }
   ],
   "source": [
    "create_model_test_effnetb2 = create_effnetb2()\n",
    "create_model_test_effnetb0 = create_effnetb0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "932bb609-e18c-4aa6-9534-83d210145456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 3]              --                   Partial\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1408, 7, 7]     --                   False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   (864)                False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   (64)                 False\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   (1,448)              False\n",
       "│    │    └─MBConv (1)                                       [32, 16, 112, 112]   [32, 16, 112, 112]   (612)                False\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     (6,004)              False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n",
       "│    │    └─MBConv (2)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 48, 28, 28]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 48, 28, 28]     (16,518)             False\n",
       "│    │    └─MBConv (1)                                       [32, 48, 28, 28]     [32, 48, 28, 28]     (43,308)             False\n",
       "│    │    └─MBConv (2)                                       [32, 48, 28, 28]     [32, 48, 28, 28]     (43,308)             False\n",
       "│    └─Sequential (4)                                        [32, 48, 28, 28]     [32, 88, 14, 14]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 48, 28, 28]     [32, 88, 14, 14]     (50,300)             False\n",
       "│    │    └─MBConv (1)                                       [32, 88, 14, 14]     [32, 88, 14, 14]     (123,750)            False\n",
       "│    │    └─MBConv (2)                                       [32, 88, 14, 14]     [32, 88, 14, 14]     (123,750)            False\n",
       "│    │    └─MBConv (3)                                       [32, 88, 14, 14]     [32, 88, 14, 14]     (123,750)            False\n",
       "│    └─Sequential (5)                                        [32, 88, 14, 14]     [32, 120, 14, 14]    --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 88, 14, 14]     [32, 120, 14, 14]    (149,158)            False\n",
       "│    │    └─MBConv (1)                                       [32, 120, 14, 14]    [32, 120, 14, 14]    (237,870)            False\n",
       "│    │    └─MBConv (2)                                       [32, 120, 14, 14]    [32, 120, 14, 14]    (237,870)            False\n",
       "│    │    └─MBConv (3)                                       [32, 120, 14, 14]    [32, 120, 14, 14]    (237,870)            False\n",
       "│    └─Sequential (6)                                        [32, 120, 14, 14]    [32, 208, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 120, 14, 14]    [32, 208, 7, 7]      (301,406)            False\n",
       "│    │    └─MBConv (1)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      (686,868)            False\n",
       "│    │    └─MBConv (2)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      (686,868)            False\n",
       "│    │    └─MBConv (3)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      (686,868)            False\n",
       "│    │    └─MBConv (4)                                       [32, 208, 7, 7]      [32, 208, 7, 7]      (686,868)            False\n",
       "│    └─Sequential (7)                                        [32, 208, 7, 7]      [32, 352, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 208, 7, 7]      [32, 352, 7, 7]      (846,900)            False\n",
       "│    │    └─MBConv (1)                                       [32, 352, 7, 7]      [32, 352, 7, 7]      (1,888,920)          False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 352, 7, 7]      [32, 1408, 7, 7]     --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 352, 7, 7]      [32, 1408, 7, 7]     (495,616)            False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1408, 7, 7]     [32, 1408, 7, 7]     (2,816)              False\n",
       "│    │    └─SiLU (2)                                         [32, 1408, 7, 7]     [32, 1408, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1408, 7, 7]     [32, 1408, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1408]           [32, 3]              --                   True\n",
       "│    └─Dropout (0)                                           [32, 1408]           [32, 1408]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1408]           [32, 3]              4,227                True\n",
       "============================================================================================================================================\n",
       "Total params: 7,705,221\n",
       "Trainable params: 4,227\n",
       "Non-trainable params: 7,700,994\n",
       "Total mult-adds (G): 21.04\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 5017.53\n",
       "Params size (MB): 30.82\n",
       "Estimated Total Size (MB): 5067.62\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=create_model_test_effnetb2,\n",
    "       input_size=(32, 3, 224, 224),\n",
    "       col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "       col_width=20,\n",
    "       row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c656f826-e18e-454d-a78a-e5b207e97f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 3]              --                   Partial\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   (864)                False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   (64)                 False\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   (1,448)              False\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     (6,004)              False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     (10,710)             False\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     (15,350)             False\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     (31,290)             False\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     (37,130)             False\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     (102,900)            False\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    (126,004)            False\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    (208,572)            False\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      (262,492)            False\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      (587,952)            False\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   False\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      (717,232)            False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   False\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     (409,600)            False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     (2,560)              False\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1280]           [32, 3]              --                   True\n",
       "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1280]           [32, 3]              3,843                True\n",
       "============================================================================================================================================\n",
       "Total params: 4,011,391\n",
       "Trainable params: 3,843\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (G): 12.31\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.09\n",
       "Params size (MB): 16.05\n",
       "Estimated Total Size (MB): 3487.41\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=create_model_test_effnetb0,\n",
    "       input_size=(32, 3, 224, 224),\n",
    "       col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "       col_width=20,\n",
    "       row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e2e2c7-752b-44a9-87fb-77cdf12cc6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
